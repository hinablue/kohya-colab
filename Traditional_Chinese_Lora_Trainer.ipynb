{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# ⭐ Lora 訓練器 by Hollowstrawberry\n",
        "\n",
        "基於 [Kohya-ss](https://github.com/kohya-ss/sd-scripts) 與 [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb) 來完成此工具，感謝。\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ8clWTZEu-g"
      },
      "source": [
        "### ⭕ 免則聲明\n",
        "本文件是用於研究機器學習等前端技術為目的。\n",
        "請閱讀以下文件說明 [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) 與 [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dPQlB4djNm3C"
      },
      "source": [
        "| |GitHub|🇬🇧 English|🇪🇸 Spanish|🇹🇼 繁體中文|\n",
        "|:--|:-:|:-:|:-:|:-:|\n",
        "| 🏠 **首頁** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| 📊 **資料集製作器** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) | |\n",
        "| ⭐ **Lora 訓練器** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) | [![在 Colab 開啟](https://raw.githubusercontent.com/hinablue/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hinablue/kohya-colab/blob/main/Traditional_Chinese_Dataset_Maker.ipynb) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OglZzI_ujZq-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import toml\n",
        "import shutil\n",
        "import zipfile\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# These carry information from past executions\n",
        "if \"model_url\" in globals():\n",
        "  old_model_url = model_url\n",
        "else:\n",
        "  old_model_url = None\n",
        "if \"dependencies_installed\" not in globals():\n",
        "  dependencies_installed = False\n",
        "if \"model_file\" not in globals():\n",
        "  model_file = None\n",
        "\n",
        "# These may be set by other cells, some are legacy\n",
        "if \"custom_dataset\" not in globals():\n",
        "  custom_dataset = None\n",
        "if \"override_dataset_config_file\" not in globals():\n",
        "  override_dataset_config_file = None\n",
        "if \"override_config_file\" not in globals():\n",
        "  override_config_file = None\n",
        "if \"optimizer\" not in globals():\n",
        "  optimizer = \"AdamW8bit\"\n",
        "if \"optimizer_args\" not in globals():\n",
        "  optimizer_args = None\n",
        "if \"continue_from_lora\" not in globals():\n",
        "  continue_from_lora = \"\"\n",
        "if \"weighted_captions\" not in globals():\n",
        "  weighted_captions = False\n",
        "if \"adjust_tags\" not in globals():\n",
        "  adjust_tags = False\n",
        "if \"keep_tokens_weight\" not in globals():\n",
        "  keep_tokens_weight = 1.0\n",
        "\n",
        "COLAB = True # low ram\n",
        "COMMIT = \"v0.6.3\"\n",
        "BETTER_EPOCH_NAMES = True\n",
        "LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#@title ## 🚩 Start Here\n",
        "\n",
        "#@markdown ### ▶️ 設定\n",
        "#@markdown 你的專案名稱必須和包含圖片的資料夾名稱相同。不允許使用空格。\n",
        "project_name = \"\" #@param {type:\"string\"}\n",
        "#@markdown 資料夾結構不重要，只是為了方便。請確保每次都選擇相同的結構。我傾向使用以專案模式的方式。\n",
        "folder_structure = \"專案模式 (MyDrive/Loras/project_name/dataset)\" #@param [\"分類模式 (MyDrive/lora_training/datasets/project_name)\", \"專案模式 (MyDrive/Loras/project_name/dataset)\"]\n",
        "#@markdown 選擇並下載訓練所需要使用的模型。這些選項應該會產生乾淨且一致的結果。你也可以選擇自己的模型，只要貼上下載連結即可。\n",
        "training_model = \"Anime (animefull-final-pruned-fp16.safetensors)\" #@param [\"Anime (animefull-final-pruned-fp16.safetensors)\", \"AnyLora (AnyLoRA_noVae_fp16-pruned.ckpt)\", \"Stable Diffusion (sd-v1-5-pruned-noema-fp16.safetensors)\"]\n",
        "#@markdown 自訂模型的下載連結。如果你沒有自訂模型，請留空。\n",
        "optional_custom_training_model_url = \"\" #@param {type:\"string\"}\n",
        "#@markdown 如果你的自訂模型是基於 Stable Diffusion 2.0，請勾選此選項。\n",
        "custom_model_is_based_on_sd2 = False #@param {type:\"boolean\"}\n",
        "\n",
        "if optional_custom_training_model_url:\n",
        "  model_url = optional_custom_training_model_url\n",
        "elif \"AnyLora\" in training_model:\n",
        "  model_url = \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.ckpt\"\n",
        "elif \"Anime\" in training_model:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/animefull-final-pruned-fp16.safetensors\"\n",
        "else:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/sd-v1-5-pruned-noema-fp16.safetensors\"\n",
        "\n",
        "#@markdown ### ▶️ 加工處理\n",
        "#@markdown 512 的解析度是 Stable Diffusion 1.5 的標準。更高的解析度會讓訓練速度變慢，但是可以產生更好的細節。\n",
        "#@markdown 圖片會在訓練時自動縮放，所以你不需要自己裁切或縮放圖片。\n",
        "resolution = 512 #@param {type:\"slider\", min:512, max:1024, step:16}\n",
        "#@markdown 這個選項會在訓練時自動翻轉圖片，不會增加訓練時間，但是可以讓模型學習更多。如果你的圖片少於 20 張，請務必開啟此選項。\n",
        "#@markdown **如果你在意圖片的對稱性，請關閉此選項。**\n",
        "flip_aug = False #@param {type:\"boolean\"}\n",
        "#markdown 提示詞檔案的副檔名，若無提示詞請留下空白。\n",
        "caption_extension = \".txt\" #param {type:\"string\"}\n",
        "#@markdown 針對動畫標籤進行洗牌可以提高學習和提示的效果。文字檔案開頭的啟動標籤，不會被洗牌。\n",
        "shuffle_tags = True #@param {type:\"boolean\"}\n",
        "shuffle_caption = shuffle_tags\n",
        "#@markdown 啟動標籤數量。如果你的圖片沒有啟動標籤，請設定為 0。請務必確認你的啟動標籤放在文字檔案的最前面。\n",
        "activation_tags = \"1\" #@param [0,1,2,3]\n",
        "keep_tokens = int(activation_tags)\n",
        "\n",
        "#@markdown ### ▶️ 步數\n",
        "#@markdown 你的圖片會在訓練時重複這個次數。我建議你的圖片乘以重複次數介於 200 到 400 之間。\n",
        "num_repeats = 10 #@param {type:\"number\"}\n",
        "#@markdown Choose how long you want to train for. A good starting point is around 10 epochs or around 2000 steps.\n",
        "#@markdown 選擇你想要訓練的時間。一個好的起點是 10 個輪次（Epoch） 或 2000 個步數（Steps)。\n",
        "#@markdown 每一個輪次（Epoch）的步數等於：你的圖片數量乘以重複次數，除以批次大小。\n",
        "preferred_unit = \"Epochs\" #@param [\"Epochs\", \"Steps\"]\n",
        "how_many = 10 #@param {type:\"number\"}\n",
        "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
        "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
        "#@markdown Saving more epochs will let you compare your Lora's progress better.\n",
        "#@markdown 儲存每次的輪次（Epochs）可以讓你更好的比較你的 Lora 的進度。\n",
        "save_every_n_epochs = 1 #@param {type:\"number\"}\n",
        "keep_only_last_n_epochs = 10 #@param {type:\"number\"}\n",
        "if not save_every_n_epochs:\n",
        "  save_every_n_epochs = max_train_epochs\n",
        "if not keep_only_last_n_epochs:\n",
        "  keep_only_last_n_epochs = max_train_epochs\n",
        "#@markdown 增加批次大小可以讓訓練更快，但是可能會讓學習變差。建議 2 或 3。\n",
        "train_batch_size = 2 #@param {type:\"slider\", min:1, max:8, step:1}\n",
        "\n",
        "#@markdown ### ▶️ 學習設定\n",
        "#@markdown 學習率是你的結果最重要的因素。如果你想要訓練更慢，或是你的圖片數量很多，或是你的 dim 和 alpha 很高，請把 UNet 的學習率調到 2e-4 或更低。\n",
        "#@markdown 文字編碼器可以讓你的 Lora 學習概念更好。建議你把文字編碼器的學習率設定為 UNet 的一半或五分之一。如果你在訓練風格，你甚至可以把它設定為 0。\n",
        "unet_lr = 2e-4 #@param {type:\"number\"}\n",
        "text_encoder_lr = 1e-4 #@param {type:\"number\"}\n",
        "#@markdown The scheduler is the algorithm that guides the learning rate. If you're not sure, pick `constant` and ignore the number. I personally recommend `cosine_with_restarts` with 3 restarts.\n",
        "#@markdown 調度器是指導學習率的演算法。如果你不確定，請選擇 `constant` 並忽略重啟數字（`lr_scheduler_number`）。若使用 `cosine_with_restarts` ，我個人建議使用 3 次重啟數字。\n",
        "lr_scheduler = \"cosine_with_restarts\" #@param [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\"]\n",
        "lr_scheduler_number = 3 #@param {type:\"number\"}\n",
        "lr_scheduler_num_cycles = lr_scheduler_number if lr_scheduler == \"cosine_with_restarts\" else 0\n",
        "lr_scheduler_power = lr_scheduler_number if lr_scheduler == \"polynomial\" else 0\n",
        "#@markdown Steps spent \"warming up\" the learning rate during training for efficiency. I recommend leaving it at 5%.\n",
        "#@markdown 在訓練時，用來「熱身」學習率的步數（僅適用於 `constant_with_warmup`）。我建議你把它設定為 5%。\n",
        "lr_warmup_ratio = 0.05 #@param {type:\"slider\", min:0.0, max:0.5, step:0.01}\n",
        "lr_warmup_steps = 0\n",
        "#@markdown New feature that adjusts loss over time, makes learning much more efficient, and training can be done with about half as many epochs. Uses a value of 5.0 as recommended by [the paper](https://arxiv.org/abs/2303.09556).\n",
        "#@markdown 新功能，可以隨著時間調整損失函數，讓學習更有效率，並且可以用大約一半的輪次（Epochs）完成訓練。參考[論文](https://arxiv.org/abs/2303.09556)建議，使用 5% 的數值。\n",
        "min_snr_gamma = True #@param {type:\"boolean\"}\n",
        "min_snr_gamma_value = 5.0 if min_snr_gamma else None\n",
        "\n",
        "#@markdown ### ▶️ 模型結構\n",
        "#@markdown LoRA 是經典的類型，而 LoCon/LoHa 則是適合風格類型的訓練。在 WebUI 中使用 LyCORIS 需要[這個擴充功能](https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris)。若想要更多資訊，請參考[這裡](https://github.com/KohakuBlueleaf/Lycoris)。\n",
        "lora_type = \"LoRA\" #@param [\"LoRA\", \"LoCon Lycoris\", \"LoHa Lycoris\"]\n",
        "\n",
        "#@markdown 以下是一些推薦的設定值：\n",
        "\n",
        "#@markdown | 類型 | network_dim | network_alpha | conv_dim | conv_alpha |\n",
        "#@markdown | :---: | :---: | :---: | :---: | :---: |\n",
        "#@markdown | LoRA | 32 | 16 |   |   |\n",
        "#@markdown | LoCon | 16 | 8 | 8 | 1 |\n",
        "#@markdown | LoHa | 8 | 4 | 4 | 1 |\n",
        "\n",
        "#@markdown 更大的 dim 代表更大的 Lora，它可以儲存更多資訊，但是並不是越大越好。建議的 dim 為 8-32，alpha 則是 dim 的一半。\n",
        "network_dim = 16 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "network_alpha = 8 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "#@markdown 以下的數值不會影響 LoRA。它們的作用類似於 dim/alpha，但僅適用於 LyCORIS 的額外學習層。\n",
        "conv_dim = 8 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "conv_alpha = 1 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "conv_compression = False #@param {type:\"boolean\"}\n",
        "\n",
        "network_module = \"lycoris.kohya\" if \"Lycoris\" in lora_type else \"networks.lora\"\n",
        "network_args = None if lora_type == \"LoRA\" else [\n",
        "  f\"conv_dim={conv_dim}\",\n",
        "  f\"conv_alpha={conv_alpha}\",\n",
        "]\n",
        "if \"Lycoris\" in lora_type:\n",
        "  network_args.append(f\"algo={'loha' if 'LoHa' in lora_type else 'lora'}\")\n",
        "  network_args.append(f\"disable_conv_cp={str(not conv_compression)}\")\n",
        "\n",
        "#@markdown ### ▶️ 更多設定\n",
        "#@markdown 建議使用 0.15 ~ 0.4 之間的數值，數值越大，訓練生成的結果越接近正規化圖片。\n",
        "prior_loss_weight = 0.1 #@param {type:\"number\"}\n",
        "#@markdown 噪訊偏移可以改善亮度/暗度的處理結果。\n",
        "noise_offset = 0.1 #@param {type:\"number\"}\n",
        "#@markdown 黑魔法，建議值使用 2，若訓練真實人物等模型，可以使用 1。\n",
        "clip_skip = 2 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown 最大文字標籤長度，預設為 225。\n",
        "max_token_length = 225 #@param [75,125,225]\n",
        "#@markdown Enable bucket no upscale, set to False if you want to using min/max bucket resolution.\n",
        "#@markdown 啟用不放大批次解析度，如果你想要使用 最大/最小 批次解析度，請設定為 `False`。\n",
        "bucket_no_upscale = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **以下設定僅適用於不放大批次解析度為 `False` 時。**\n",
        "\n",
        "#@markdown 若解析度小於 512，建議使用 256，否則建議使用 320。\n",
        "min_bucket_reso = 256 #@param {type:\"number\"}\n",
        "#@markdown 若解析度小於 512，建議使用 1024，否則建議使用 1280。\n",
        "max_bucket_reso = 1024 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown 顏色增強可以改善結果的顏色。如果啟用，將會強制關閉快取潛在變數快取（`Latent Cache = False`）。\n",
        "color_aug = False #@param {type:\"boolean\"}\n",
        "#@markdown 依據臉部中心尺寸擷取圖片，再依此上限、下限決定擷取的範圍。可優化臉部訓練。若訓練包含背景風格可將此數值上限、下限加大。\n",
        "face_crop_aug_range = [1.0, 3.0] #@param {type:\"raw\"}\n",
        "#@markdown Random crop the image, recommend using False.\n",
        "#@markdown 隨機擷取圖片區域，建議使用 `False`，若訓練風格類型則建議開啟。\n",
        "random_crop = False #@param {type:\"boolean\"}\n",
        "#@markdown 增加梯度累積步驟以節省 GPU 記憶體。但會降低訓練速度，並需要更高的學習率。\n",
        "gradient_accumulation_steps = 1 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### ▶️ 實驗性功能\n",
        "#@markdown 儲存額外資料，約 1 GB，可以讓你稍後繼續訓練。\n",
        "save_state = False #@param {type:\"boolean\"}\n",
        "#@markdown 如果有儲存的額外資料，則繼續訓練。\n",
        "resume = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### ▶️ 準備好了\n",
        "#@markdown 你現在可以執行此儲存格來開始訓練。祝你好運！\n",
        "\n",
        "# 👩‍💻 Cool code goes here\n",
        "\n",
        "if optimizer == \"DAdaptation\":\n",
        "  optimizer_args = [\"decouple=True\",\"weight_decay=0.02\"]\n",
        "  unet_lr = 0.5\n",
        "  text_encoder_lr = 0.5\n",
        "  lr_scheduler = \"constant_with_warmup\"\n",
        "  network_alpha = network_dim\n",
        "\n",
        "root_dir = \"/content\" if COLAB else \"~/Loras\"\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "\n",
        "if \"/Loras\" in folder_structure:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
        "  log_folder    = os.path.join(main_dir, \"_logs\")\n",
        "  config_folder = os.path.join(main_dir, project_name)\n",
        "  images_folder = os.path.join(main_dir, project_name, \"dataset\")\n",
        "  output_folder = os.path.join(main_dir, project_name, \"output\")\n",
        "else:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
        "  images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "  output_folder = os.path.join(main_dir, \"output\", project_name)\n",
        "  config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "  log_folder    = os.path.join(main_dir, \"log\")\n",
        "\n",
        "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
        "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
        "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "def clone_repo():\n",
        "  os.chdir(root_dir)\n",
        "  !git clone https://github.com/kohya-ss/sd-scripts {repo_dir}\n",
        "  os.chdir(repo_dir)\n",
        "  if COMMIT:\n",
        "    !git reset --hard {COMMIT}\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/requirements.txt -q -O requirements.txt\n",
        "\n",
        "def install_dependencies():\n",
        "  clone_repo()\n",
        "  !apt -y update -qq\n",
        "  !apt -y install aria2\n",
        "  !pip -q install --upgrade -r requirements.txt\n",
        "\n",
        "  # patch kohya for minor stuff\n",
        "  if COLAB:\n",
        "    !sed -i \"s@cpu@cuda@\" library/model_util.py # low ram\n",
        "  if LOAD_TRUNCATED_IMAGES:\n",
        "    !sed -i 's/from PIL import Image/from PIL import Image, ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES=True/g' library/train_util.py # fix truncated jpegs error\n",
        "  if BETTER_EPOCH_NAMES:\n",
        "    !sed -i 's/{:06d}/{:02d}/g' library/train_util.py # make epoch names shorter\n",
        "    !sed -i 's/model_name + \".\"/model_name + \"-{:02d}.\".format(num_train_epochs)/g' train_network.py # name of the last epoch will match the rest\n",
        "\n",
        "  from accelerate.utils import write_basic_config\n",
        "  if not os.path.exists(accelerate_config_file):\n",
        "    write_basic_config(save_location=accelerate_config_file)\n",
        "\n",
        "  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "  os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"  \n",
        "  os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "def validate_dataset():\n",
        "  global lr_warmup_steps, lr_warmup_ratio, caption_extension, keep_tokens, keep_tokens_weight, weighted_captions, adjust_tags\n",
        "  supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "  print(\"\\n💿 檢查資料集...\")\n",
        "  if not project_name.strip() or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
        "    print(\"💥 錯誤：請選擇正確的專案名稱。\")\n",
        "    return\n",
        "\n",
        "  if custom_dataset:\n",
        "    try:\n",
        "      datconf = toml.loads(custom_dataset)\n",
        "      datasets = {d[\"image_dir\"]: d[\"num_repeats\"] for d in datconf[\"datasets\"][0][\"subsets\"]}\n",
        "    except:\n",
        "      print(f\"💥 錯誤：你的自訂資料集結構錯誤，請確認資料集結構。\")\n",
        "      return\n",
        "    folders = datasets.keys()\n",
        "    files = [f for folder in folders for f in os.listdir(folder)]\n",
        "    images_repeats = {folder: (len([f for f in os.listdir(folder) if f.lower().endswith(supported_types)]), datasets[folder]) for folder in folders}\n",
        "  else:\n",
        "    folders = [images_folder]\n",
        "    files = os.listdir(images_folder)\n",
        "    images_repeats = {images_folder: (len([f for f in files if f.lower().endswith(supported_types)]), num_repeats)}\n",
        "\n",
        "  for folder in folders:\n",
        "    if not os.path.exists(folder):\n",
        "      print(f\"💥 錯誤：資料夾 {folder.replace('/content/drive/', '')} 不存在。\")\n",
        "      return\n",
        "  for folder, (img, rep) in images_repeats.items():\n",
        "    if not img:\n",
        "      print(f\"💥 錯誤：你的 {folder.replace('/content/drive/', '')} 資料夾沒有資料。\")\n",
        "      return\n",
        "  for f in files:\n",
        "    if not f.lower().endswith(\".txt\") and not f.lower().endswith(supported_types):\n",
        "      print(f\"💥 錯誤：錯誤的資料集結構 \\\"{f}\\\"，中斷執行。\")\n",
        "      return\n",
        "    \n",
        "  if not [txt for txt in files if txt.lower().endswith(\".txt\")]:\n",
        "    caption_extension = \"\"\n",
        "  if continue_from_lora and not (continue_from_lora.endswith(\".safetensors\") and os.path.exists(continue_from_lora)):\n",
        "    print(f\"💥 錯誤：錯誤的路徑或 Lora 不存在。範例：/content/drive/MyDrive/Loras/example.safetensors\")\n",
        "    return\n",
        "\n",
        "  pre_steps_per_epoch = sum(img*rep for (img, rep) in images_repeats.values())\n",
        "  steps_per_epoch = pre_steps_per_epoch/train_batch_size\n",
        "  total_steps = max_train_steps or int(max_train_epochs*steps_per_epoch)\n",
        "  estimated_epochs = int(total_steps/steps_per_epoch)\n",
        "  lr_warmup_steps = int(total_steps*lr_warmup_ratio)\n",
        "\n",
        "  for folder, (img, rep) in images_repeats.items():\n",
        "    print(\"📁\"+folder.replace(\"/content/drive/\", \"\"))\n",
        "    print(f\"📈 讀取 {img} 圖片，重複 {rep} 次，共有 {img*rep} 個步驟。\")\n",
        "  print(f\"📉 訓練批次 {train_batch_size} 除以每一輪次步驟 {pre_steps_per_epoch} 得到每一輪次處理 {steps_per_epoch} 個步驟。\")\n",
        "  if max_train_epochs:\n",
        "    print(f\"🔮 最大輪次 {max_train_epochs}，大約會有 {total_steps} 個總訓練步驟。\")\n",
        "  else:\n",
        "    print(f\"🔮 總訓練步驟 {total_steps}，並除以 {estimated_epochs} 個輪次。\")\n",
        "\n",
        "  if total_steps > 18000:\n",
        "    print(\"💥 錯誤：你的總訓練步驟過高，可能會造成錯誤。中斷訓練。\") \n",
        "    return\n",
        "\n",
        "  if adjust_tags:\n",
        "    print(f\"\\n📎 設定權重標籤：{'開啟' if weighted_captions else '關閉'}\")\n",
        "    if weighted_captions:\n",
        "      print(f\"📎 將對 {keep_tokens} 個啟動標籤設定 {keep_tokens_weight} 權重。\")\n",
        "    print(\"📎 調整標籤...\")\n",
        "    adjust_weighted_tags(folders, keep_tokens, keep_tokens_weight, weighted_captions)\n",
        "  \n",
        "  return True\n",
        "\n",
        "def adjust_weighted_tags(folders, keep_tokens: int, keep_tokens_weight: float, weighted_captions: bool):\n",
        "  weighted_tag = re.compile(r\"\\((.+?):[.\\d]+\\)(,|$)\")\n",
        "  for folder in folders:\n",
        "    for txt in [f for f in os.listdir(folder) if f.lower().endswith(\".txt\")]:\n",
        "      with open(os.path.join(folder, txt), 'r') as f:\n",
        "        content = f.read()\n",
        "      # reset previous changes\n",
        "      content = content.replace('\\\\', '')\n",
        "      content = weighted_tag.sub(r'\\1\\2', content)\n",
        "      if weighted_captions:\n",
        "        # re-apply changes\n",
        "        content = content.replace(r'(', r'\\(').replace(r')', r'\\)').replace(r':', r'\\:')\n",
        "        if keep_tokens_weight > 1:\n",
        "          tags = [s.strip() for s in content.split(\",\")]\n",
        "          for i in range(min(keep_tokens, len(tags))):\n",
        "            tags[i] = f'({tags[i]}:{keep_tokens_weight})'\n",
        "          content = \", \".join(tags)\n",
        "      with open(os.path.join(folder, txt), 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "def create_config():\n",
        "  global dataset_config_file, config_file, model_file\n",
        "\n",
        "  if resume:\n",
        "    resume_points = [f.path for f in os.scandir(output_folder) if f.is_dir()]\n",
        "    resume_points.sort()\n",
        "    last_resume_point = resume_points[-1] if resume_points else None\n",
        "  else:\n",
        "    last_resume_point = None\n",
        "\n",
        "  if override_config_file:\n",
        "    config_file = override_config_file\n",
        "    print(f\"\\n⭕ 使用自訂設定檔 {config_file}\")\n",
        "  else:\n",
        "    config_dict = {\n",
        "      \"additional_network_arguments\": {\n",
        "        \"unet_lr\": unet_lr,\n",
        "        \"text_encoder_lr\": text_encoder_lr,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": True if text_encoder_lr == 0 else None,\n",
        "        \"network_weights\": continue_from_lora if continue_from_lora else None\n",
        "      },\n",
        "      \"optimizer_arguments\": {\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps if lr_scheduler != \"constant\" else None,\n",
        "        \"optimizer_type\": optimizer,\n",
        "        \"optimizer_args\": optimizer_args if optimizer_args else None,\n",
        "      },\n",
        "      \"training_arguments\": {\n",
        "        \"max_train_steps\": max_train_steps,\n",
        "        \"max_train_epochs\": max_train_epochs,\n",
        "        \"save_every_n_epochs\": save_every_n_epochs,\n",
        "        \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"noise_offset\": noise_offset if noise_offset > 0 else None,\n",
        "        \"clip_skip\": clip_skip if clip_skip > 0 else None,\n",
        "        \"min_snr_gamma\": min_snr_gamma_value,\n",
        "        \"weighted_captions\": weighted_captions,\n",
        "        \"seed\": 42,\n",
        "        \"max_token_length\": max_token_length,\n",
        "        \"xformers\": True,\n",
        "        \"lowram\": COLAB,\n",
        "        \"max_data_loader_n_workers\": 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"save_precision\": \"fp16\",\n",
        "        \"mixed_precision\": \"fp16\",\n",
        "        \"output_dir\": output_folder,\n",
        "        \"logging_dir\": log_folder,\n",
        "        \"output_name\": project_name,\n",
        "        \"log_prefix\": project_name,\n",
        "        \"save_state\": save_state,\n",
        "        \"save_last_n_epochs_state\": 1 if save_state else None,\n",
        "        \"resume\": last_resume_point,\n",
        "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "      },\n",
        "      \"model_arguments\": {\n",
        "        \"pretrained_model_name_or_path\": model_file,\n",
        "        \"v2\": custom_model_is_based_on_sd2,\n",
        "        \"v_parameterization\": True if custom_model_is_based_on_sd2 else None,\n",
        "      },\n",
        "      \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\",\n",
        "      },\n",
        "      \"dreambooth_arguments\": {\n",
        "        \"prior_loss_weight\": prior_loss_weight,\n",
        "      },\n",
        "      \"dataset_arguments\": {\n",
        "        \"cache_latents\": True if color_aug == True else False,\n",
        "      },\n",
        "    }\n",
        "\n",
        "    for key in config_dict:\n",
        "      if isinstance(config_dict[key], dict):\n",
        "        config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(config_dict))\n",
        "    print(f\"\\n📄 設定檔已儲存到 {config_file}\")\n",
        "\n",
        "  if override_dataset_config_file:\n",
        "    dataset_config_file = override_dataset_config_file\n",
        "    print(f\"⭕ 使用自訂資料集設定檔 {dataset_config_file}\")\n",
        "  else:\n",
        "    dataset_config_dict = {\n",
        "      \"general\": {\n",
        "        \"resolution\": resolution,\n",
        "        \"shuffle_caption\": shuffle_caption,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"flip_aug\": flip_aug,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"enable_bucket\": True,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": bucket_no_upscale,\n",
        "        \"min_bucket_reso\": min_bucket_reso,\n",
        "        \"max_bucket_reso\": max_bucket_reso,\n",
        "        \"color_aug\": color_aug,\n",
        "        \"face_crop_aug_range\": face_crop_aug_range,\n",
        "        \"random_crop\": random_crop,\n",
        "      },\n",
        "      \"datasets\": toml.loads(custom_dataset)[\"datasets\"] if custom_dataset else [\n",
        "        {\n",
        "          \"subsets\": [\n",
        "            {\n",
        "              \"num_repeats\": num_repeats,\n",
        "              \"image_dir\": images_folder,\n",
        "              \"class_tokens\": None if caption_extension else project_name\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "\n",
        "    for key in dataset_config_dict:\n",
        "      if isinstance(dataset_config_dict[key], dict):\n",
        "        dataset_config_dict[key] = {k: v for k, v in dataset_config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(dataset_config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(dataset_config_dict))\n",
        "    print(f\"📄 資料集設定檔已儲存到 {dataset_config_file}\")\n",
        "\n",
        "def download_model():\n",
        "  global old_model_url, model_url, model_file\n",
        "  real_model_url = model_url.strip()\n",
        "  \n",
        "  if real_model_url.lower().endswith((\".ckpt\", \".safetensors\")):\n",
        "    model_file = f\"/content{real_model_url[real_model_url.rfind('/'):]}\"\n",
        "  else:\n",
        "    model_file = \"/content/downloaded_model.safetensors\"\n",
        "    if os.path.exists(model_file):\n",
        "      !rm \"{model_file}\"\n",
        "\n",
        "  if m := re.search(r\"(?:https?://)?(?:www\\.)?huggingface\\.co/[^/]+/[^/]+/blob\", model_url):\n",
        "    real_model_url = real_model_url.replace(\"blob\", \"resolve\")\n",
        "  elif m := re.search(r\"(?:https?://)?(?:www\\.)?civitai\\.com/models/([0-9]+)\", model_url):\n",
        "    real_model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "\n",
        "  !aria2c \"{real_model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
        "\n",
        "  if model_file.lower().endswith(\".safetensors\"):\n",
        "    from safetensors.torch import load_file as load_safetensors\n",
        "    try:\n",
        "      test = load_safetensors(model_file)\n",
        "      del test\n",
        "    except Exception as e:\n",
        "      #if \"HeaderTooLarge\" in str(e):\n",
        "      new_model_file = os.path.splitext(model_file)[0]+\".ckpt\"\n",
        "      !mv \"{model_file}\" \"{new_model_file}\"\n",
        "      model_file = new_model_file\n",
        "      print(f\"Renamed model to {os.path.splitext(model_file)[0]}.ckpt\")\n",
        "\n",
        "  if model_file.lower().endswith(\".ckpt\"):\n",
        "    from torch import load as load_ckpt\n",
        "    try:\n",
        "      test = load_ckpt(model_file)\n",
        "      del test\n",
        "    except Exception as e:\n",
        "      return False\n",
        "      \n",
        "  return True\n",
        "\n",
        "def main():\n",
        "  global dependencies_installed\n",
        "\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"📂 連接到 Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "  \n",
        "  for dir in (main_dir, deps_dir, repo_dir, log_folder, images_folder, output_folder, config_folder):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  if not validate_dataset():\n",
        "    return\n",
        "  \n",
        "  if not dependencies_installed:\n",
        "    print(\"\\n🏭 安裝相依套件...\\n\")\n",
        "    t0 = time()\n",
        "    install_dependencies()\n",
        "    t1 = time()\n",
        "    dependencies_installed = True\n",
        "    print(f\"\\n✅ 安裝完成，使用 {int(t1-t0)} 秒。\")\n",
        "  else:\n",
        "    print(\"\\n✅ 相依套件已安裝完成。\")\n",
        "\n",
        "  if old_model_url != model_url or not model_file or not os.path.exists(model_file):\n",
        "    print(\"\\n🔄 下載模型中...\")\n",
        "    if not download_model():\n",
        "      print(\"\\n💥 錯誤：你的模型錯誤或無法下載，你可以使用 Civitai 或 Huggingface 連結，或任何可以直接下載的連結。\")\n",
        "      return\n",
        "    print()\n",
        "  else:\n",
        "    print(\"\\n🔄 模型已經下載。\\n\")\n",
        "\n",
        "  create_config()\n",
        "  \n",
        "  print(\"\\n⭐ GPU 資訊...\\n\")\n",
        "  !nvidia-smi -L\n",
        "\n",
        "  print(\"\\n⭐ 開始訓練...\\n\")\n",
        "  os.chdir(repo_dir)\n",
        "  \n",
        "  !accelerate launch --config_file={accelerate_config_file} --num_cpu_threads_per_process=2 train_network.py --dataset_config={dataset_config_file} --config_file={config_file}\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    display(Markdown(\"### ✅ 完成！[前往你的 Google Drive 下載](https://drive.google.com/drive/my-drive)\"))\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mBMUJ7BuvNcn"
      },
      "source": [
        "## *️⃣ 擴充功能\n",
        "\n",
        "在開始訓練之前，你可以執行以下的功能。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd4916Eu1tb9"
      },
      "source": [
        "### 📚 複數資料夾的資料集\n",
        "以下的樣版允許你在資料集中，定義複數的資料夾。你需要包含每個資料集的檔案路徑，且指定每個資料集的重複次數。你可以直接複製 `[[datasets.subsets]]` 區塊，簡單的增加你的資料集。\n",
        "\n",
        "當你使用這個設定，在原本訓練中的重複次數的設定將會被忽略，且依據專案的資料集設定也會被忽略。\n",
        "\n",
        "你可以加入 `ìs_reg = true` 將某一個資料集設定為正規化（regularization）資料。\n",
        "你也可以設定各種不同的參數，例如 `keep_tokens`, `flip_aug` 等等。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y037lagnJWmn"
      },
      "outputs": [],
      "source": [
        "custom_dataset = \"\"\"\n",
        "[[datasets]]\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/example/dataset/good_images\"\n",
        "num_repeats = 3\n",
        "is_reg = false\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/example/dataset/normal_images\"\n",
        "num_repeats = 1\n",
        "is_reg = false\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/example/dataset/reg_images\"\n",
        "num_repeats = 1\n",
        "is_reg = true\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W84Jxf-U2TIU"
      },
      "outputs": [],
      "source": [
        "custom_dataset = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sy9jU2yrdYar"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 🔮 進階設定\n",
        "#@markdown 改變訓練時使用的優化器，`AdamW8bit` 是推薦的預設值。\n",
        "#@markdown 選擇 DAdaptation 優化器（會使用自動管理學習率）會覆蓋以下設定：\n",
        "#@markdown `learning_rate=0.5`, `lr_scheduler=\"constant_with_warmup\"`, `optimizer_args=decouple=True,weight_decay=0.02`, `network_alpha=network_dim`\n",
        "optimizer = \"AdamW8bit\" #@param [\"AdamW8bit\", \"AdamW\", \"Lion\", \"DAdaptation\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
        "optimizer_args = \"weight_decay=0.1\" #@param {type:\"string\"}\n",
        "optimizer_args = [a.strip() for a in optimizer_args.split(\",\") if a]\n",
        "\n",
        "#@markdown 權重標籤是一個新功能，允許你使用（括號）來給予資料集中某些標籤更多的權重，就像在網頁界面提示中一樣。\n",
        "#@markdown 正常括號在你的標籤中，例如 `(series names)`，需要像 `\\(series names\\)` 這樣跳脫。\n",
        "weighted_captions = False #@param {type:\"boolean\"}\n",
        "\n",
        "#markdown By enabling `adjust_tags`, you will let this colab modify your tags before running to automatically adjust to `weighted_captions` being on or off. \n",
        "#@markdown 若啟用 `adjust_tags`，你將允許此 colab 在執行前修改你的標籤，以自動調整 `weighted_captions` 的開關。\n",
        "adjust_tags = False #@param {type:\"boolean\"}\n",
        "activation_tag_weight = \"1.0\" #@param [\"1.0\",\"1.1\",\"1.2\"]\n",
        "keep_tokens_weight = float(activation_tag_weight)\n",
        "\n",
        "#@markdown 你可以在這裡寫下你的 Google Drive 中的路徑，以載入現有的 Lora 檔案，以繼續訓練。\n",
        "#@markdown **警告** 這不是一個長時間的訓練階段。每個 epoch 都是從頭開始，並且可能會有更差的結果。\n",
        "continue_from_lora = \"\" #@param {type:\"string\"}\n",
        "if continue_from_lora and not continue_from_lora.startswith(\"/content/drive/MyDrive\"):\n",
        "  import os\n",
        "  continue_from_lora = os.path.join(\"/content/drive/MyDrive\", continue_from_lora)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WDjkp4scvPgE"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 📂 解壓縮資料集\n",
        "#@markdown 上傳資料集檔案是一個很慢的過程，如果你有一個 zip 檔案，你可能想要上傳一個 zip 檔案到你的雲端硬碟。\n",
        "zip = \"/content/drive/MyDrive/my_dataset.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"📂 Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"✅ Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKWlpsG0jrX3"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 🔢 計算資料集\n",
        "#@markdown Google Drive 無法計算資料夾中的檔案數，因此這將顯示所有資料夾和子資料夾中的檔案數。\n",
        "folder = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"📂 Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"📁{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
