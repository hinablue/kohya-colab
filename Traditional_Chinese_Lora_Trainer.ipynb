{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# ‚≠ê Lora Ë®ìÁ∑¥Âô® by Hollowstrawberry\n",
        "\n",
        "Âü∫Êñº [Kohya-ss](https://github.com/kohya-ss/sd-scripts) Ëàá [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb) ‰æÜÂÆåÊàêÊ≠§Â∑•ÂÖ∑ÔºåÊÑüË¨ù„ÄÇ\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vJ8clWTZEu-g"
      },
      "source": [
        "### ‚≠ï ÂÖçÂâáËÅ≤Êòé\n",
        "Êú¨Êñá‰ª∂ÊòØÁî®ÊñºÁ†îÁ©∂Ê©üÂô®Â≠∏ÁøíÁ≠âÂâçÁ´ØÊäÄË°ìÁÇ∫ÁõÆÁöÑ„ÄÇ\n",
        "Ë´ãÈñ±ËÆÄ‰ª•‰∏ãÊñá‰ª∂Ë™™Êòé [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) Ëàá [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dPQlB4djNm3C"
      },
      "source": [
        "| |GitHub|üá¨üáß English|üá™üá∏ Spanish|üáπüáº ÁπÅÈ´î‰∏≠Êñá|\n",
        "|:--|:-:|:-:|:-:|:-:|\n",
        "| üè† **È¶ñÈ†Å** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| üìä **Ë≥áÊñôÈõÜË£Ω‰ΩúÂô®** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) | |\n",
        "| ‚≠ê **Lora Ë®ìÁ∑¥Âô®** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) | [![Âú® Colab ÈñãÂïü](https://raw.githubusercontent.com/hinablue/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hinablue/kohya-colab/blob/main/Traditional_Chinese_Dataset_Maker.ipynb) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OglZzI_ujZq-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import toml\n",
        "import shutil\n",
        "import zipfile\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# These carry information from past executions\n",
        "if \"model_url\" in globals():\n",
        "  old_model_url = model_url\n",
        "else:\n",
        "  old_model_url = None\n",
        "if \"dependencies_installed\" not in globals():\n",
        "  dependencies_installed = False\n",
        "if \"model_file\" not in globals():\n",
        "  model_file = None\n",
        "\n",
        "# These may be set by other cells, some are legacy\n",
        "if \"custom_dataset\" not in globals():\n",
        "  custom_dataset = None\n",
        "if \"override_dataset_config_file\" not in globals():\n",
        "  override_dataset_config_file = None\n",
        "if \"override_config_file\" not in globals():\n",
        "  override_config_file = None\n",
        "if \"optimizer\" not in globals():\n",
        "  optimizer = \"AdamW8bit\"\n",
        "if \"optimizer_args\" not in globals():\n",
        "  optimizer_args = None\n",
        "if \"continue_from_lora\" not in globals():\n",
        "  continue_from_lora = \"\"\n",
        "if \"weighted_captions\" not in globals():\n",
        "  weighted_captions = False\n",
        "if \"adjust_tags\" not in globals():\n",
        "  adjust_tags = False\n",
        "if \"keep_tokens_weight\" not in globals():\n",
        "  keep_tokens_weight = 1.0\n",
        "\n",
        "COLAB = True # low ram\n",
        "COMMIT = \"v0.6.3\"\n",
        "BETTER_EPOCH_NAMES = True\n",
        "LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#@title ## üö© Start Here\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Ë®≠ÂÆö\n",
        "#@markdown ‰Ω†ÁöÑÂ∞àÊ°àÂêçÁ®±ÂøÖÈ†àÂíåÂåÖÂê´ÂúñÁâáÁöÑË≥áÊñôÂ§æÂêçÁ®±Áõ∏Âêå„ÄÇ‰∏çÂÖÅË®±‰ΩøÁî®Á©∫Ê†º„ÄÇ\n",
        "project_name = \"\" #@param {type:\"string\"}\n",
        "#@markdown Ë≥áÊñôÂ§æÁµêÊßã‰∏çÈáçË¶ÅÔºåÂè™ÊòØÁÇ∫‰∫ÜÊñπ‰æø„ÄÇË´ãÁ¢∫‰øùÊØèÊ¨°ÈÉΩÈÅ∏ÊìáÁõ∏ÂêåÁöÑÁµêÊßã„ÄÇÊàëÂÇæÂêë‰ΩøÁî®‰ª•Â∞àÊ°àÊ®°ÂºèÁöÑÊñπÂºè„ÄÇ\n",
        "folder_structure = \"Â∞àÊ°àÊ®°Âºè (MyDrive/Loras/project_name/dataset)\" #@param [\"ÂàÜÈ°ûÊ®°Âºè (MyDrive/lora_training/datasets/project_name)\", \"Â∞àÊ°àÊ®°Âºè (MyDrive/Loras/project_name/dataset)\"]\n",
        "#@markdown ÈÅ∏Êìá‰∏¶‰∏ãËºâË®ìÁ∑¥ÊâÄÈúÄË¶Å‰ΩøÁî®ÁöÑÊ®°Âûã„ÄÇÈÄô‰∫õÈÅ∏È†ÖÊáâË©≤ÊúÉÁî¢Áîü‰πæÊ∑®‰∏î‰∏ÄËá¥ÁöÑÁµêÊûú„ÄÇ‰Ω†‰πüÂèØ‰ª•ÈÅ∏ÊìáËá™Â∑±ÁöÑÊ®°ÂûãÔºåÂè™Ë¶ÅË≤º‰∏ä‰∏ãËºâÈÄ£ÁµêÂç≥ÂèØ„ÄÇ\n",
        "training_model = \"Anime (animefull-final-pruned-fp16.safetensors)\" #@param [\"Anime (animefull-final-pruned-fp16.safetensors)\", \"AnyLora (AnyLoRA_noVae_fp16-pruned.ckpt)\", \"Stable Diffusion (sd-v1-5-pruned-noema-fp16.safetensors)\"]\n",
        "#@markdown Ëá™Ë®ÇÊ®°ÂûãÁöÑ‰∏ãËºâÈÄ£Áµê„ÄÇÂ¶ÇÊûú‰Ω†Ê≤íÊúâËá™Ë®ÇÊ®°ÂûãÔºåË´ãÁïôÁ©∫„ÄÇ\n",
        "optional_custom_training_model_url = \"\" #@param {type:\"string\"}\n",
        "#@markdown Â¶ÇÊûú‰Ω†ÁöÑËá™Ë®ÇÊ®°ÂûãÊòØÂü∫Êñº Stable Diffusion 2.0ÔºåË´ãÂãæÈÅ∏Ê≠§ÈÅ∏È†Ö„ÄÇ\n",
        "custom_model_is_based_on_sd2 = False #@param {type:\"boolean\"}\n",
        "\n",
        "if optional_custom_training_model_url:\n",
        "  model_url = optional_custom_training_model_url\n",
        "elif \"AnyLora\" in training_model:\n",
        "  model_url = \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.ckpt\"\n",
        "elif \"Anime\" in training_model:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/animefull-final-pruned-fp16.safetensors\"\n",
        "else:\n",
        "  model_url = \"https://huggingface.co/hollowstrawberry/stable-diffusion-guide/resolve/main/models/sd-v1-5-pruned-noema-fp16.safetensors\"\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Âä†Â∑•ËôïÁêÜ\n",
        "#@markdown 512 ÁöÑËß£ÊûêÂ∫¶ÊòØ Stable Diffusion 1.5 ÁöÑÊ®ôÊ∫ñ„ÄÇÊõ¥È´òÁöÑËß£ÊûêÂ∫¶ÊúÉËÆìË®ìÁ∑¥ÈÄüÂ∫¶ËÆäÊÖ¢Ôºå‰ΩÜÊòØÂèØ‰ª•Áî¢ÁîüÊõ¥Â•ΩÁöÑÁ¥∞ÁØÄ„ÄÇ\n",
        "#@markdown ÂúñÁâáÊúÉÂú®Ë®ìÁ∑¥ÊôÇËá™ÂãïÁ∏ÆÊîæÔºåÊâÄ‰ª•‰Ω†‰∏çÈúÄË¶ÅËá™Â∑±Ë£ÅÂàáÊàñÁ∏ÆÊîæÂúñÁâá„ÄÇ\n",
        "resolution = 512 #@param {type:\"slider\", min:512, max:1024, step:16}\n",
        "#@markdown ÈÄôÂÄãÈÅ∏È†ÖÊúÉÂú®Ë®ìÁ∑¥ÊôÇËá™ÂãïÁøªËΩâÂúñÁâáÔºå‰∏çÊúÉÂ¢ûÂä†Ë®ìÁ∑¥ÊôÇÈñìÔºå‰ΩÜÊòØÂèØ‰ª•ËÆìÊ®°ÂûãÂ≠∏ÁøíÊõ¥Â§ö„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÂúñÁâáÂ∞ëÊñº 20 ÂºµÔºåË´ãÂãôÂøÖÈñãÂïüÊ≠§ÈÅ∏È†Ö„ÄÇ\n",
        "#@markdown **Â¶ÇÊûú‰Ω†Âú®ÊÑèÂúñÁâáÁöÑÂ∞çÁ®±ÊÄßÔºåË´ãÈóúÈñâÊ≠§ÈÅ∏È†Ö„ÄÇ**\n",
        "flip_aug = False #@param {type:\"boolean\"}\n",
        "#markdown ÊèêÁ§∫Ë©ûÊ™îÊ°àÁöÑÂâØÊ™îÂêçÔºåËã•ÁÑ°ÊèêÁ§∫Ë©ûË´ãÁïô‰∏ãÁ©∫ÁôΩ„ÄÇ\n",
        "caption_extension = \".txt\" #param {type:\"string\"}\n",
        "#@markdown ÈáùÂ∞çÂãïÁï´Ê®ôÁ±§ÈÄ≤Ë°åÊ¥óÁâåÂèØ‰ª•ÊèêÈ´òÂ≠∏ÁøíÂíåÊèêÁ§∫ÁöÑÊïàÊûú„ÄÇÊñáÂ≠óÊ™îÊ°àÈñãÈ†≠ÁöÑÂïüÂãïÊ®ôÁ±§Ôºå‰∏çÊúÉË¢´Ê¥óÁâå„ÄÇ\n",
        "shuffle_tags = True #@param {type:\"boolean\"}\n",
        "shuffle_caption = shuffle_tags\n",
        "#@markdown ÂïüÂãïÊ®ôÁ±§Êï∏Èáè„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÂúñÁâáÊ≤íÊúâÂïüÂãïÊ®ôÁ±§ÔºåË´ãË®≠ÂÆöÁÇ∫ 0„ÄÇË´ãÂãôÂøÖÁ¢∫Ë™ç‰Ω†ÁöÑÂïüÂãïÊ®ôÁ±§ÊîæÂú®ÊñáÂ≠óÊ™îÊ°àÁöÑÊúÄÂâçÈù¢„ÄÇ\n",
        "activation_tags = \"1\" #@param [0,1,2,3]\n",
        "keep_tokens = int(activation_tags)\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Ê≠•Êï∏\n",
        "#@markdown ‰Ω†ÁöÑÂúñÁâáÊúÉÂú®Ë®ìÁ∑¥ÊôÇÈáçË§áÈÄôÂÄãÊ¨°Êï∏„ÄÇÊàëÂª∫Ë≠∞‰Ω†ÁöÑÂúñÁâá‰πò‰ª•ÈáçË§áÊ¨°Êï∏‰ªãÊñº 200 Âà∞ 400 ‰πãÈñì„ÄÇ\n",
        "num_repeats = 10 #@param {type:\"number\"}\n",
        "#@markdown Choose how long you want to train for. A good starting point is around 10 epochs or around 2000 steps.\n",
        "#@markdown ÈÅ∏Êìá‰Ω†ÊÉ≥Ë¶ÅË®ìÁ∑¥ÁöÑÊôÇÈñì„ÄÇ‰∏ÄÂÄãÂ•ΩÁöÑËµ∑ÈªûÊòØ 10 ÂÄãËº™Ê¨°ÔºàEpochÔºâ Êàñ 2000 ÂÄãÊ≠•Êï∏ÔºàSteps)„ÄÇ\n",
        "#@markdown ÊØè‰∏ÄÂÄãËº™Ê¨°ÔºàEpochÔºâÁöÑÊ≠•Êï∏Á≠âÊñºÔºö‰Ω†ÁöÑÂúñÁâáÊï∏Èáè‰πò‰ª•ÈáçË§áÊ¨°Êï∏ÔºåÈô§‰ª•ÊâπÊ¨°Â§ßÂ∞è„ÄÇ\n",
        "preferred_unit = \"Epochs\" #@param [\"Epochs\", \"Steps\"]\n",
        "how_many = 10 #@param {type:\"number\"}\n",
        "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
        "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
        "#@markdown Saving more epochs will let you compare your Lora's progress better.\n",
        "#@markdown ÂÑ≤Â≠òÊØèÊ¨°ÁöÑËº™Ê¨°ÔºàEpochsÔºâÂèØ‰ª•ËÆì‰Ω†Êõ¥Â•ΩÁöÑÊØîËºÉ‰Ω†ÁöÑ Lora ÁöÑÈÄ≤Â∫¶„ÄÇ\n",
        "save_every_n_epochs = 1 #@param {type:\"number\"}\n",
        "keep_only_last_n_epochs = 10 #@param {type:\"number\"}\n",
        "if not save_every_n_epochs:\n",
        "  save_every_n_epochs = max_train_epochs\n",
        "if not keep_only_last_n_epochs:\n",
        "  keep_only_last_n_epochs = max_train_epochs\n",
        "#@markdown Â¢ûÂä†ÊâπÊ¨°Â§ßÂ∞èÂèØ‰ª•ËÆìË®ìÁ∑¥Êõ¥Âø´Ôºå‰ΩÜÊòØÂèØËÉΩÊúÉËÆìÂ≠∏ÁøíËÆäÂ∑Æ„ÄÇÂª∫Ë≠∞ 2 Êàñ 3„ÄÇ\n",
        "train_batch_size = 2 #@param {type:\"slider\", min:1, max:8, step:1}\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Â≠∏ÁøíË®≠ÂÆö\n",
        "#@markdown Â≠∏ÁøíÁéáÊòØ‰Ω†ÁöÑÁµêÊûúÊúÄÈáçË¶ÅÁöÑÂõ†Á¥†„ÄÇÂ¶ÇÊûú‰Ω†ÊÉ≥Ë¶ÅË®ìÁ∑¥Êõ¥ÊÖ¢ÔºåÊàñÊòØ‰Ω†ÁöÑÂúñÁâáÊï∏ÈáèÂæàÂ§öÔºåÊàñÊòØ‰Ω†ÁöÑ dim Âíå alpha ÂæàÈ´òÔºåË´ãÊää UNet ÁöÑÂ≠∏ÁøíÁéáË™øÂà∞ 2e-4 ÊàñÊõ¥‰Ωé„ÄÇ\n",
        "#@markdown ÊñáÂ≠óÁ∑®Á¢ºÂô®ÂèØ‰ª•ËÆì‰Ω†ÁöÑ Lora Â≠∏ÁøíÊ¶ÇÂøµÊõ¥Â•Ω„ÄÇÂª∫Ë≠∞‰Ω†ÊääÊñáÂ≠óÁ∑®Á¢ºÂô®ÁöÑÂ≠∏ÁøíÁéáË®≠ÂÆöÁÇ∫ UNet ÁöÑ‰∏ÄÂçäÊàñ‰∫îÂàÜ‰πã‰∏Ä„ÄÇÂ¶ÇÊûú‰Ω†Âú®Ë®ìÁ∑¥È¢®Ê†ºÔºå‰Ω†ÁîöËá≥ÂèØ‰ª•ÊääÂÆÉË®≠ÂÆöÁÇ∫ 0„ÄÇ\n",
        "unet_lr = 2e-4 #@param {type:\"number\"}\n",
        "text_encoder_lr = 1e-4 #@param {type:\"number\"}\n",
        "#@markdown The scheduler is the algorithm that guides the learning rate. If you're not sure, pick `constant` and ignore the number. I personally recommend `cosine_with_restarts` with 3 restarts.\n",
        "#@markdown Ë™øÂ∫¶Âô®ÊòØÊåáÂ∞éÂ≠∏ÁøíÁéáÁöÑÊºîÁÆóÊ≥ï„ÄÇÂ¶ÇÊûú‰Ω†‰∏çÁ¢∫ÂÆöÔºåË´ãÈÅ∏Êìá `constant` ‰∏¶ÂøΩÁï•ÈáçÂïüÊï∏Â≠óÔºà`lr_scheduler_number`Ôºâ„ÄÇËã•‰ΩøÁî® `cosine_with_restarts` ÔºåÊàëÂÄã‰∫∫Âª∫Ë≠∞‰ΩøÁî® 3 Ê¨°ÈáçÂïüÊï∏Â≠ó„ÄÇ\n",
        "lr_scheduler = \"cosine_with_restarts\" #@param [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\"]\n",
        "lr_scheduler_number = 3 #@param {type:\"number\"}\n",
        "lr_scheduler_num_cycles = lr_scheduler_number if lr_scheduler == \"cosine_with_restarts\" else 0\n",
        "lr_scheduler_power = lr_scheduler_number if lr_scheduler == \"polynomial\" else 0\n",
        "#@markdown Steps spent \"warming up\" the learning rate during training for efficiency. I recommend leaving it at 5%.\n",
        "#@markdown Âú®Ë®ìÁ∑¥ÊôÇÔºåÁî®‰æÜ„ÄåÁÜ±Ë∫´„ÄçÂ≠∏ÁøíÁéáÁöÑÊ≠•Êï∏ÔºàÂÉÖÈÅ©Áî®Êñº `constant_with_warmup`Ôºâ„ÄÇÊàëÂª∫Ë≠∞‰Ω†ÊääÂÆÉË®≠ÂÆöÁÇ∫ 5%„ÄÇ\n",
        "lr_warmup_ratio = 0.05 #@param {type:\"slider\", min:0.0, max:0.5, step:0.01}\n",
        "lr_warmup_steps = 0\n",
        "#@markdown New feature that adjusts loss over time, makes learning much more efficient, and training can be done with about half as many epochs. Uses a value of 5.0 as recommended by [the paper](https://arxiv.org/abs/2303.09556).\n",
        "#@markdown Êñ∞ÂäüËÉΩÔºåÂèØ‰ª•Èö®ËëóÊôÇÈñìË™øÊï¥ÊêçÂ§±ÂáΩÊï∏ÔºåËÆìÂ≠∏ÁøíÊõ¥ÊúâÊïàÁéáÔºå‰∏¶‰∏îÂèØ‰ª•Áî®Â§ßÁ¥Ñ‰∏ÄÂçäÁöÑËº™Ê¨°ÔºàEpochsÔºâÂÆåÊàêË®ìÁ∑¥„ÄÇÂèÉËÄÉ[Ë´ñÊñá](https://arxiv.org/abs/2303.09556)Âª∫Ë≠∞Ôºå‰ΩøÁî® 5% ÁöÑÊï∏ÂÄº„ÄÇ\n",
        "min_snr_gamma = True #@param {type:\"boolean\"}\n",
        "min_snr_gamma_value = 5.0 if min_snr_gamma else None\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Ê®°ÂûãÁµêÊßã\n",
        "#@markdown LoRA ÊòØÁ∂ìÂÖ∏ÁöÑÈ°ûÂûãÔºåËÄå LoCon/LoHa ÂâáÊòØÈÅ©ÂêàÈ¢®Ê†ºÈ°ûÂûãÁöÑË®ìÁ∑¥„ÄÇÂú® WebUI ‰∏≠‰ΩøÁî® LyCORIS ÈúÄË¶Å[ÈÄôÂÄãÊì¥ÂÖÖÂäüËÉΩ](https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris)„ÄÇËã•ÊÉ≥Ë¶ÅÊõ¥Â§öË≥áË®äÔºåË´ãÂèÉËÄÉ[ÈÄôË£°](https://github.com/KohakuBlueleaf/Lycoris)„ÄÇ\n",
        "lora_type = \"LoRA\" #@param [\"LoRA\", \"LoCon Lycoris\", \"LoHa Lycoris\"]\n",
        "\n",
        "#@markdown ‰ª•‰∏ãÊòØ‰∏Ä‰∫õÊé®Ëñ¶ÁöÑË®≠ÂÆöÂÄºÔºö\n",
        "\n",
        "#@markdown | È°ûÂûã | network_dim | network_alpha | conv_dim | conv_alpha |\n",
        "#@markdown | :---: | :---: | :---: | :---: | :---: |\n",
        "#@markdown | LoRA | 32 | 16 |   |   |\n",
        "#@markdown | LoCon | 16 | 8 | 8 | 1 |\n",
        "#@markdown | LoHa | 8 | 4 | 4 | 1 |\n",
        "\n",
        "#@markdown Êõ¥Â§ßÁöÑ dim ‰ª£Ë°®Êõ¥Â§ßÁöÑ LoraÔºåÂÆÉÂèØ‰ª•ÂÑ≤Â≠òÊõ¥Â§öË≥áË®äÔºå‰ΩÜÊòØ‰∏¶‰∏çÊòØË∂äÂ§ßË∂äÂ•Ω„ÄÇÂª∫Ë≠∞ÁöÑ dim ÁÇ∫ 8-32Ôºåalpha ÂâáÊòØ dim ÁöÑ‰∏ÄÂçä„ÄÇ\n",
        "network_dim = 16 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "network_alpha = 8 #@param {type:\"slider\", min:1, max:128, step:1}\n",
        "#@markdown ‰ª•‰∏ãÁöÑÊï∏ÂÄº‰∏çÊúÉÂΩ±Èüø LoRA„ÄÇÂÆÉÂÄëÁöÑ‰ΩúÁî®È°û‰ººÊñº dim/alphaÔºå‰ΩÜÂÉÖÈÅ©Áî®Êñº LyCORIS ÁöÑÈ°çÂ§ñÂ≠∏ÁøíÂ±§„ÄÇ\n",
        "conv_dim = 8 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "conv_alpha = 1 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "conv_compression = False #@param {type:\"boolean\"}\n",
        "\n",
        "network_module = \"lycoris.kohya\" if \"Lycoris\" in lora_type else \"networks.lora\"\n",
        "network_args = None if lora_type == \"LoRA\" else [\n",
        "  f\"conv_dim={conv_dim}\",\n",
        "  f\"conv_alpha={conv_alpha}\",\n",
        "]\n",
        "if \"Lycoris\" in lora_type:\n",
        "  network_args.append(f\"algo={'loha' if 'LoHa' in lora_type else 'lora'}\")\n",
        "  network_args.append(f\"disable_conv_cp={str(not conv_compression)}\")\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Êõ¥Â§öË®≠ÂÆö\n",
        "#@markdown Âª∫Ë≠∞‰ΩøÁî® 0.15 ~ 0.4 ‰πãÈñìÁöÑÊï∏ÂÄºÔºåÊï∏ÂÄºË∂äÂ§ßÔºåË®ìÁ∑¥ÁîüÊàêÁöÑÁµêÊûúË∂äÊé•ËøëÊ≠£Ë¶èÂåñÂúñÁâá„ÄÇ\n",
        "prior_loss_weight = 0.1 #@param {type:\"number\"}\n",
        "#@markdown Âô™Ë®äÂÅèÁßªÂèØ‰ª•ÊîπÂñÑ‰∫ÆÂ∫¶/ÊöóÂ∫¶ÁöÑËôïÁêÜÁµêÊûú„ÄÇ\n",
        "noise_offset = 0.1 #@param {type:\"number\"}\n",
        "#@markdown ÈªëÈ≠îÊ≥ïÔºåÂª∫Ë≠∞ÂÄº‰ΩøÁî® 2ÔºåËã•Ë®ìÁ∑¥ÁúüÂØ¶‰∫∫Áâ©Á≠âÊ®°ÂûãÔºåÂèØ‰ª•‰ΩøÁî® 1„ÄÇ\n",
        "clip_skip = 2 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown ÊúÄÂ§ßÊñáÂ≠óÊ®ôÁ±§Èï∑Â∫¶ÔºåÈ†êË®≠ÁÇ∫ 225„ÄÇ\n",
        "max_token_length = 225 #@param [75,125,225]\n",
        "#@markdown Enable bucket no upscale, set to False if you want to using min/max bucket resolution.\n",
        "#@markdown ÂïüÁî®‰∏çÊîæÂ§ßÊâπÊ¨°Ëß£ÊûêÂ∫¶ÔºåÂ¶ÇÊûú‰Ω†ÊÉ≥Ë¶Å‰ΩøÁî® ÊúÄÂ§ß/ÊúÄÂ∞è ÊâπÊ¨°Ëß£ÊûêÂ∫¶ÔºåË´ãË®≠ÂÆöÁÇ∫ `False`„ÄÇ\n",
        "bucket_no_upscale = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown **‰ª•‰∏ãË®≠ÂÆöÂÉÖÈÅ©Áî®Êñº‰∏çÊîæÂ§ßÊâπÊ¨°Ëß£ÊûêÂ∫¶ÁÇ∫ `False` ÊôÇ„ÄÇ**\n",
        "\n",
        "#@markdown Ëã•Ëß£ÊûêÂ∫¶Â∞èÊñº 512ÔºåÂª∫Ë≠∞‰ΩøÁî® 256ÔºåÂê¶ÂâáÂª∫Ë≠∞‰ΩøÁî® 320„ÄÇ\n",
        "min_bucket_reso = 256 #@param {type:\"number\"}\n",
        "#@markdown Ëã•Ëß£ÊûêÂ∫¶Â∞èÊñº 512ÔºåÂª∫Ë≠∞‰ΩøÁî® 1024ÔºåÂê¶ÂâáÂª∫Ë≠∞‰ΩøÁî® 1280„ÄÇ\n",
        "max_bucket_reso = 1024 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown È°èËâ≤Â¢ûÂº∑ÂèØ‰ª•ÊîπÂñÑÁµêÊûúÁöÑÈ°èËâ≤„ÄÇÂ¶ÇÊûúÂïüÁî®ÔºåÂ∞áÊúÉÂº∑Âà∂ÈóúÈñâÂø´ÂèñÊΩõÂú®ËÆäÊï∏Âø´ÂèñÔºà`Latent Cache = False`Ôºâ„ÄÇ\n",
        "color_aug = False #@param {type:\"boolean\"}\n",
        "#@markdown ‰æùÊìöËáâÈÉ®‰∏≠ÂøÉÂ∞∫ÂØ∏Êì∑ÂèñÂúñÁâáÔºåÂÜç‰æùÊ≠§‰∏äÈôê„ÄÅ‰∏ãÈôêÊ±∫ÂÆöÊì∑ÂèñÁöÑÁØÑÂúç„ÄÇÂèØÂÑ™ÂåñËáâÈÉ®Ë®ìÁ∑¥„ÄÇËã•Ë®ìÁ∑¥ÂåÖÂê´ËÉåÊôØÈ¢®Ê†ºÂèØÂ∞áÊ≠§Êï∏ÂÄº‰∏äÈôê„ÄÅ‰∏ãÈôêÂä†Â§ß„ÄÇ\n",
        "face_crop_aug_range = [1.0, 3.0] #@param {type:\"raw\"}\n",
        "#@markdown Random crop the image, recommend using False.\n",
        "#@markdown Èö®Ê©üÊì∑ÂèñÂúñÁâáÂçÄÂüüÔºåÂª∫Ë≠∞‰ΩøÁî® `False`ÔºåËã•Ë®ìÁ∑¥È¢®Ê†ºÈ°ûÂûãÂâáÂª∫Ë≠∞ÈñãÂïü„ÄÇ\n",
        "random_crop = False #@param {type:\"boolean\"}\n",
        "#@markdown Â¢ûÂä†Ê¢ØÂ∫¶Á¥ØÁ©çÊ≠•È©ü‰ª•ÁØÄÁúÅ GPU Ë®òÊÜ∂È´î„ÄÇ‰ΩÜÊúÉÈôç‰ΩéË®ìÁ∑¥ÈÄüÂ∫¶Ôºå‰∏¶ÈúÄË¶ÅÊõ¥È´òÁöÑÂ≠∏ÁøíÁéá„ÄÇ\n",
        "gradient_accumulation_steps = 1 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è ÂØ¶È©óÊÄßÂäüËÉΩ\n",
        "#@markdown ÂÑ≤Â≠òÈ°çÂ§ñË≥áÊñôÔºåÁ¥Ñ 1 GBÔºåÂèØ‰ª•ËÆì‰Ω†Á®çÂæåÁπºÁ∫åË®ìÁ∑¥„ÄÇ\n",
        "save_state = False #@param {type:\"boolean\"}\n",
        "#@markdown Â¶ÇÊûúÊúâÂÑ≤Â≠òÁöÑÈ°çÂ§ñË≥áÊñôÔºåÂâáÁπºÁ∫åË®ìÁ∑¥„ÄÇ\n",
        "resume = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### ‚ñ∂Ô∏è Ê∫ñÂÇôÂ•Ω‰∫Ü\n",
        "#@markdown ‰Ω†ÁèæÂú®ÂèØ‰ª•Âü∑Ë°åÊ≠§ÂÑ≤Â≠òÊ†º‰æÜÈñãÂßãË®ìÁ∑¥„ÄÇÁ•ù‰Ω†Â•ΩÈÅãÔºÅ\n",
        "\n",
        "# üë©‚Äçüíª Cool code goes here\n",
        "\n",
        "if optimizer == \"DAdaptation\":\n",
        "  optimizer_args = [\"decouple=True\",\"weight_decay=0.02\"]\n",
        "  unet_lr = 0.5\n",
        "  text_encoder_lr = 0.5\n",
        "  lr_scheduler = \"constant_with_warmup\"\n",
        "  network_alpha = network_dim\n",
        "\n",
        "root_dir = \"/content\" if COLAB else \"~/Loras\"\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "\n",
        "if \"/Loras\" in folder_structure:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
        "  log_folder    = os.path.join(main_dir, \"_logs\")\n",
        "  config_folder = os.path.join(main_dir, project_name)\n",
        "  images_folder = os.path.join(main_dir, project_name, \"dataset\")\n",
        "  output_folder = os.path.join(main_dir, project_name, \"output\")\n",
        "else:\n",
        "  main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
        "  images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "  output_folder = os.path.join(main_dir, \"output\", project_name)\n",
        "  config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "  log_folder    = os.path.join(main_dir, \"log\")\n",
        "\n",
        "config_file = os.path.join(config_folder, \"training_config.toml\")\n",
        "dataset_config_file = os.path.join(config_folder, \"dataset_config.toml\")\n",
        "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "def clone_repo():\n",
        "  os.chdir(root_dir)\n",
        "  !git clone https://github.com/kohya-ss/sd-scripts {repo_dir}\n",
        "  os.chdir(repo_dir)\n",
        "  if COMMIT:\n",
        "    !git reset --hard {COMMIT}\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/requirements.txt -q -O requirements.txt\n",
        "\n",
        "def install_dependencies():\n",
        "  clone_repo()\n",
        "  !apt -y update -qq\n",
        "  !apt -y install aria2\n",
        "  !pip -q install --upgrade -r requirements.txt\n",
        "\n",
        "  # patch kohya for minor stuff\n",
        "  if COLAB:\n",
        "    !sed -i \"s@cpu@cuda@\" library/model_util.py # low ram\n",
        "  if LOAD_TRUNCATED_IMAGES:\n",
        "    !sed -i 's/from PIL import Image/from PIL import Image, ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES=True/g' library/train_util.py # fix truncated jpegs error\n",
        "  if BETTER_EPOCH_NAMES:\n",
        "    !sed -i 's/{:06d}/{:02d}/g' library/train_util.py # make epoch names shorter\n",
        "    !sed -i 's/model_name + \".\"/model_name + \"-{:02d}.\".format(num_train_epochs)/g' train_network.py # name of the last epoch will match the rest\n",
        "\n",
        "  from accelerate.utils import write_basic_config\n",
        "  if not os.path.exists(accelerate_config_file):\n",
        "    write_basic_config(save_location=accelerate_config_file)\n",
        "\n",
        "  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "  os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"  \n",
        "  os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "\n",
        "def validate_dataset():\n",
        "  global lr_warmup_steps, lr_warmup_ratio, caption_extension, keep_tokens, keep_tokens_weight, weighted_captions, adjust_tags\n",
        "  supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "  print(\"\\nüíø Ê™¢Êü•Ë≥áÊñôÈõÜ...\")\n",
        "  if not project_name.strip() or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
        "    print(\"üí• ÈåØË™§ÔºöË´ãÈÅ∏ÊìáÊ≠£Á¢∫ÁöÑÂ∞àÊ°àÂêçÁ®±„ÄÇ\")\n",
        "    return\n",
        "\n",
        "  if custom_dataset:\n",
        "    try:\n",
        "      datconf = toml.loads(custom_dataset)\n",
        "      datasets = {d[\"image_dir\"]: d[\"num_repeats\"] for d in datconf[\"datasets\"][0][\"subsets\"]}\n",
        "    except:\n",
        "      print(f\"üí• ÈåØË™§Ôºö‰Ω†ÁöÑËá™Ë®ÇË≥áÊñôÈõÜÁµêÊßãÈåØË™§ÔºåË´ãÁ¢∫Ë™çË≥áÊñôÈõÜÁµêÊßã„ÄÇ\")\n",
        "      return\n",
        "    folders = datasets.keys()\n",
        "    files = [f for folder in folders for f in os.listdir(folder)]\n",
        "    images_repeats = {folder: (len([f for f in os.listdir(folder) if f.lower().endswith(supported_types)]), datasets[folder]) for folder in folders}\n",
        "  else:\n",
        "    folders = [images_folder]\n",
        "    files = os.listdir(images_folder)\n",
        "    images_repeats = {images_folder: (len([f for f in files if f.lower().endswith(supported_types)]), num_repeats)}\n",
        "\n",
        "  for folder in folders:\n",
        "    if not os.path.exists(folder):\n",
        "      print(f\"üí• ÈåØË™§ÔºöË≥áÊñôÂ§æ {folder.replace('/content/drive/', '')} ‰∏çÂ≠òÂú®„ÄÇ\")\n",
        "      return\n",
        "  for folder, (img, rep) in images_repeats.items():\n",
        "    if not img:\n",
        "      print(f\"üí• ÈåØË™§Ôºö‰Ω†ÁöÑ {folder.replace('/content/drive/', '')} Ë≥áÊñôÂ§æÊ≤íÊúâË≥áÊñô„ÄÇ\")\n",
        "      return\n",
        "  for f in files:\n",
        "    if not f.lower().endswith(\".txt\") and not f.lower().endswith(supported_types):\n",
        "      print(f\"üí• ÈåØË™§ÔºöÈåØË™§ÁöÑË≥áÊñôÈõÜÁµêÊßã \\\"{f}\\\"Ôºå‰∏≠Êñ∑Âü∑Ë°å„ÄÇ\")\n",
        "      return\n",
        "    \n",
        "  if not [txt for txt in files if txt.lower().endswith(\".txt\")]:\n",
        "    caption_extension = \"\"\n",
        "  if continue_from_lora and not (continue_from_lora.endswith(\".safetensors\") and os.path.exists(continue_from_lora)):\n",
        "    print(f\"üí• ÈåØË™§ÔºöÈåØË™§ÁöÑË∑ØÂæëÊàñ Lora ‰∏çÂ≠òÂú®„ÄÇÁØÑ‰æãÔºö/content/drive/MyDrive/Loras/example.safetensors\")\n",
        "    return\n",
        "\n",
        "  pre_steps_per_epoch = sum(img*rep for (img, rep) in images_repeats.values())\n",
        "  steps_per_epoch = pre_steps_per_epoch/train_batch_size\n",
        "  total_steps = max_train_steps or int(max_train_epochs*steps_per_epoch)\n",
        "  estimated_epochs = int(total_steps/steps_per_epoch)\n",
        "  lr_warmup_steps = int(total_steps*lr_warmup_ratio)\n",
        "\n",
        "  for folder, (img, rep) in images_repeats.items():\n",
        "    print(\"üìÅ\"+folder.replace(\"/content/drive/\", \"\"))\n",
        "    print(f\"üìà ËÆÄÂèñ {img} ÂúñÁâáÔºåÈáçË§á {rep} Ê¨°ÔºåÂÖ±Êúâ {img*rep} ÂÄãÊ≠•È©ü„ÄÇ\")\n",
        "  print(f\"üìâ Ë®ìÁ∑¥ÊâπÊ¨° {train_batch_size} Èô§‰ª•ÊØè‰∏ÄËº™Ê¨°Ê≠•È©ü {pre_steps_per_epoch} ÂæóÂà∞ÊØè‰∏ÄËº™Ê¨°ËôïÁêÜ {steps_per_epoch} ÂÄãÊ≠•È©ü„ÄÇ\")\n",
        "  if max_train_epochs:\n",
        "    print(f\"üîÆ ÊúÄÂ§ßËº™Ê¨° {max_train_epochs}ÔºåÂ§ßÁ¥ÑÊúÉÊúâ {total_steps} ÂÄãÁ∏ΩË®ìÁ∑¥Ê≠•È©ü„ÄÇ\")\n",
        "  else:\n",
        "    print(f\"üîÆ Á∏ΩË®ìÁ∑¥Ê≠•È©ü {total_steps}Ôºå‰∏¶Èô§‰ª• {estimated_epochs} ÂÄãËº™Ê¨°„ÄÇ\")\n",
        "\n",
        "  if total_steps > 18000:\n",
        "    print(\"üí• ÈåØË™§Ôºö‰Ω†ÁöÑÁ∏ΩË®ìÁ∑¥Ê≠•È©üÈÅéÈ´òÔºåÂèØËÉΩÊúÉÈÄ†ÊàêÈåØË™§„ÄÇ‰∏≠Êñ∑Ë®ìÁ∑¥„ÄÇ\") \n",
        "    return\n",
        "\n",
        "  if adjust_tags:\n",
        "    print(f\"\\nüìé Ë®≠ÂÆöÊ¨äÈáçÊ®ôÁ±§Ôºö{'ÈñãÂïü' if weighted_captions else 'ÈóúÈñâ'}\")\n",
        "    if weighted_captions:\n",
        "      print(f\"üìé Â∞áÂ∞ç {keep_tokens} ÂÄãÂïüÂãïÊ®ôÁ±§Ë®≠ÂÆö {keep_tokens_weight} Ê¨äÈáç„ÄÇ\")\n",
        "    print(\"üìé Ë™øÊï¥Ê®ôÁ±§...\")\n",
        "    adjust_weighted_tags(folders, keep_tokens, keep_tokens_weight, weighted_captions)\n",
        "  \n",
        "  return True\n",
        "\n",
        "def adjust_weighted_tags(folders, keep_tokens: int, keep_tokens_weight: float, weighted_captions: bool):\n",
        "  weighted_tag = re.compile(r\"\\((.+?):[.\\d]+\\)(,|$)\")\n",
        "  for folder in folders:\n",
        "    for txt in [f for f in os.listdir(folder) if f.lower().endswith(\".txt\")]:\n",
        "      with open(os.path.join(folder, txt), 'r') as f:\n",
        "        content = f.read()\n",
        "      # reset previous changes\n",
        "      content = content.replace('\\\\', '')\n",
        "      content = weighted_tag.sub(r'\\1\\2', content)\n",
        "      if weighted_captions:\n",
        "        # re-apply changes\n",
        "        content = content.replace(r'(', r'\\(').replace(r')', r'\\)').replace(r':', r'\\:')\n",
        "        if keep_tokens_weight > 1:\n",
        "          tags = [s.strip() for s in content.split(\",\")]\n",
        "          for i in range(min(keep_tokens, len(tags))):\n",
        "            tags[i] = f'({tags[i]}:{keep_tokens_weight})'\n",
        "          content = \", \".join(tags)\n",
        "      with open(os.path.join(folder, txt), 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "def create_config():\n",
        "  global dataset_config_file, config_file, model_file\n",
        "\n",
        "  if resume:\n",
        "    resume_points = [f.path for f in os.scandir(output_folder) if f.is_dir()]\n",
        "    resume_points.sort()\n",
        "    last_resume_point = resume_points[-1] if resume_points else None\n",
        "  else:\n",
        "    last_resume_point = None\n",
        "\n",
        "  if override_config_file:\n",
        "    config_file = override_config_file\n",
        "    print(f\"\\n‚≠ï ‰ΩøÁî®Ëá™Ë®ÇË®≠ÂÆöÊ™î {config_file}\")\n",
        "  else:\n",
        "    config_dict = {\n",
        "      \"additional_network_arguments\": {\n",
        "        \"unet_lr\": unet_lr,\n",
        "        \"text_encoder_lr\": text_encoder_lr,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": True if text_encoder_lr == 0 else None,\n",
        "        \"network_weights\": continue_from_lora if continue_from_lora else None\n",
        "      },\n",
        "      \"optimizer_arguments\": {\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps if lr_scheduler != \"constant\" else None,\n",
        "        \"optimizer_type\": optimizer,\n",
        "        \"optimizer_args\": optimizer_args if optimizer_args else None,\n",
        "      },\n",
        "      \"training_arguments\": {\n",
        "        \"max_train_steps\": max_train_steps,\n",
        "        \"max_train_epochs\": max_train_epochs,\n",
        "        \"save_every_n_epochs\": save_every_n_epochs,\n",
        "        \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"noise_offset\": noise_offset if noise_offset > 0 else None,\n",
        "        \"clip_skip\": clip_skip if clip_skip > 0 else None,\n",
        "        \"min_snr_gamma\": min_snr_gamma_value,\n",
        "        \"weighted_captions\": weighted_captions,\n",
        "        \"seed\": 42,\n",
        "        \"max_token_length\": max_token_length,\n",
        "        \"xformers\": True,\n",
        "        \"lowram\": COLAB,\n",
        "        \"max_data_loader_n_workers\": 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"save_precision\": \"fp16\",\n",
        "        \"mixed_precision\": \"fp16\",\n",
        "        \"output_dir\": output_folder,\n",
        "        \"logging_dir\": log_folder,\n",
        "        \"output_name\": project_name,\n",
        "        \"log_prefix\": project_name,\n",
        "        \"save_state\": save_state,\n",
        "        \"save_last_n_epochs_state\": 1 if save_state else None,\n",
        "        \"resume\": last_resume_point,\n",
        "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
        "      },\n",
        "      \"model_arguments\": {\n",
        "        \"pretrained_model_name_or_path\": model_file,\n",
        "        \"v2\": custom_model_is_based_on_sd2,\n",
        "        \"v_parameterization\": True if custom_model_is_based_on_sd2 else None,\n",
        "      },\n",
        "      \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\",\n",
        "      },\n",
        "      \"dreambooth_arguments\": {\n",
        "        \"prior_loss_weight\": prior_loss_weight,\n",
        "      },\n",
        "      \"dataset_arguments\": {\n",
        "        \"cache_latents\": True if color_aug == True else False,\n",
        "      },\n",
        "    }\n",
        "\n",
        "    for key in config_dict:\n",
        "      if isinstance(config_dict[key], dict):\n",
        "        config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(config_dict))\n",
        "    print(f\"\\nüìÑ Ë®≠ÂÆöÊ™îÂ∑≤ÂÑ≤Â≠òÂà∞ {config_file}\")\n",
        "\n",
        "  if override_dataset_config_file:\n",
        "    dataset_config_file = override_dataset_config_file\n",
        "    print(f\"‚≠ï ‰ΩøÁî®Ëá™Ë®ÇË≥áÊñôÈõÜË®≠ÂÆöÊ™î {dataset_config_file}\")\n",
        "  else:\n",
        "    dataset_config_dict = {\n",
        "      \"general\": {\n",
        "        \"resolution\": resolution,\n",
        "        \"shuffle_caption\": shuffle_caption,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"flip_aug\": flip_aug,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"enable_bucket\": True,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": bucket_no_upscale,\n",
        "        \"min_bucket_reso\": min_bucket_reso,\n",
        "        \"max_bucket_reso\": max_bucket_reso,\n",
        "        \"color_aug\": color_aug,\n",
        "        \"face_crop_aug_range\": face_crop_aug_range,\n",
        "        \"random_crop\": random_crop,\n",
        "      },\n",
        "      \"datasets\": toml.loads(custom_dataset)[\"datasets\"] if custom_dataset else [\n",
        "        {\n",
        "          \"subsets\": [\n",
        "            {\n",
        "              \"num_repeats\": num_repeats,\n",
        "              \"image_dir\": images_folder,\n",
        "              \"class_tokens\": None if caption_extension else project_name\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "\n",
        "    for key in dataset_config_dict:\n",
        "      if isinstance(dataset_config_dict[key], dict):\n",
        "        dataset_config_dict[key] = {k: v for k, v in dataset_config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(dataset_config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(dataset_config_dict))\n",
        "    print(f\"üìÑ Ë≥áÊñôÈõÜË®≠ÂÆöÊ™îÂ∑≤ÂÑ≤Â≠òÂà∞ {dataset_config_file}\")\n",
        "\n",
        "def download_model():\n",
        "  global old_model_url, model_url, model_file\n",
        "  real_model_url = model_url.strip()\n",
        "  \n",
        "  if real_model_url.lower().endswith((\".ckpt\", \".safetensors\")):\n",
        "    model_file = f\"/content{real_model_url[real_model_url.rfind('/'):]}\"\n",
        "  else:\n",
        "    model_file = \"/content/downloaded_model.safetensors\"\n",
        "    if os.path.exists(model_file):\n",
        "      !rm \"{model_file}\"\n",
        "\n",
        "  if m := re.search(r\"(?:https?://)?(?:www\\.)?huggingface\\.co/[^/]+/[^/]+/blob\", model_url):\n",
        "    real_model_url = real_model_url.replace(\"blob\", \"resolve\")\n",
        "  elif m := re.search(r\"(?:https?://)?(?:www\\.)?civitai\\.com/models/([0-9]+)\", model_url):\n",
        "    real_model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "\n",
        "  !aria2c \"{real_model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
        "\n",
        "  if model_file.lower().endswith(\".safetensors\"):\n",
        "    from safetensors.torch import load_file as load_safetensors\n",
        "    try:\n",
        "      test = load_safetensors(model_file)\n",
        "      del test\n",
        "    except Exception as e:\n",
        "      #if \"HeaderTooLarge\" in str(e):\n",
        "      new_model_file = os.path.splitext(model_file)[0]+\".ckpt\"\n",
        "      !mv \"{model_file}\" \"{new_model_file}\"\n",
        "      model_file = new_model_file\n",
        "      print(f\"Renamed model to {os.path.splitext(model_file)[0]}.ckpt\")\n",
        "\n",
        "  if model_file.lower().endswith(\".ckpt\"):\n",
        "    from torch import load as load_ckpt\n",
        "    try:\n",
        "      test = load_ckpt(model_file)\n",
        "      del test\n",
        "    except Exception as e:\n",
        "      return False\n",
        "      \n",
        "  return True\n",
        "\n",
        "def main():\n",
        "  global dependencies_installed\n",
        "\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"üìÇ ÈÄ£Êé•Âà∞ Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "  \n",
        "  for dir in (main_dir, deps_dir, repo_dir, log_folder, images_folder, output_folder, config_folder):\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  if not validate_dataset():\n",
        "    return\n",
        "  \n",
        "  if not dependencies_installed:\n",
        "    print(\"\\nüè≠ ÂÆâË£ùÁõ∏‰æùÂ•ó‰ª∂...\\n\")\n",
        "    t0 = time()\n",
        "    install_dependencies()\n",
        "    t1 = time()\n",
        "    dependencies_installed = True\n",
        "    print(f\"\\n‚úÖ ÂÆâË£ùÂÆåÊàêÔºå‰ΩøÁî® {int(t1-t0)} Áßí„ÄÇ\")\n",
        "  else:\n",
        "    print(\"\\n‚úÖ Áõ∏‰æùÂ•ó‰ª∂Â∑≤ÂÆâË£ùÂÆåÊàê„ÄÇ\")\n",
        "\n",
        "  if old_model_url != model_url or not model_file or not os.path.exists(model_file):\n",
        "    print(\"\\nüîÑ ‰∏ãËºâÊ®°Âûã‰∏≠...\")\n",
        "    if not download_model():\n",
        "      print(\"\\nüí• ÈåØË™§Ôºö‰Ω†ÁöÑÊ®°ÂûãÈåØË™§ÊàñÁÑ°Ê≥ï‰∏ãËºâÔºå‰Ω†ÂèØ‰ª•‰ΩøÁî® Civitai Êàñ Huggingface ÈÄ£ÁµêÔºåÊàñ‰ªª‰ΩïÂèØ‰ª•Áõ¥Êé•‰∏ãËºâÁöÑÈÄ£Áµê„ÄÇ\")\n",
        "      return\n",
        "    print()\n",
        "  else:\n",
        "    print(\"\\nüîÑ Ê®°ÂûãÂ∑≤Á∂ì‰∏ãËºâ„ÄÇ\\n\")\n",
        "\n",
        "  create_config()\n",
        "  \n",
        "  print(\"\\n‚≠ê GPU Ë≥áË®ä...\\n\")\n",
        "  !nvidia-smi -L\n",
        "\n",
        "  print(\"\\n‚≠ê ÈñãÂßãË®ìÁ∑¥...\\n\")\n",
        "  os.chdir(repo_dir)\n",
        "  \n",
        "  !accelerate launch --config_file={accelerate_config_file} --num_cpu_threads_per_process=2 train_network.py --dataset_config={dataset_config_file} --config_file={config_file}\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    display(Markdown(\"### ‚úÖ ÂÆåÊàêÔºÅ[ÂâçÂæÄ‰Ω†ÁöÑ Google Drive ‰∏ãËºâ](https://drive.google.com/drive/my-drive)\"))\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mBMUJ7BuvNcn"
      },
      "source": [
        "## *Ô∏è‚É£ Êì¥ÂÖÖÂäüËÉΩ\n",
        "\n",
        "Âú®ÈñãÂßãË®ìÁ∑¥‰πãÂâçÔºå‰Ω†ÂèØ‰ª•Âü∑Ë°å‰ª•‰∏ãÁöÑÂäüËÉΩ„ÄÇ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd4916Eu1tb9"
      },
      "source": [
        "### üìö Ë§áÊï∏Ë≥áÊñôÂ§æÁöÑË≥áÊñôÈõÜ\n",
        "‰ª•‰∏ãÁöÑÊ®£ÁâàÂÖÅË®±‰Ω†Âú®Ë≥áÊñôÈõÜ‰∏≠ÔºåÂÆöÁæ©Ë§áÊï∏ÁöÑË≥áÊñôÂ§æ„ÄÇ‰Ω†ÈúÄË¶ÅÂåÖÂê´ÊØèÂÄãË≥áÊñôÈõÜÁöÑÊ™îÊ°àË∑ØÂæëÔºå‰∏îÊåáÂÆöÊØèÂÄãË≥áÊñôÈõÜÁöÑÈáçË§áÊ¨°Êï∏„ÄÇ‰Ω†ÂèØ‰ª•Áõ¥Êé•Ë§áË£Ω `[[datasets.subsets]]` ÂçÄÂ°äÔºåÁ∞°ÂñÆÁöÑÂ¢ûÂä†‰Ω†ÁöÑË≥áÊñôÈõÜ„ÄÇ\n",
        "\n",
        "Áï∂‰Ω†‰ΩøÁî®ÈÄôÂÄãË®≠ÂÆöÔºåÂú®ÂéüÊú¨Ë®ìÁ∑¥‰∏≠ÁöÑÈáçË§áÊ¨°Êï∏ÁöÑË®≠ÂÆöÂ∞áÊúÉË¢´ÂøΩÁï•Ôºå‰∏î‰æùÊìöÂ∞àÊ°àÁöÑË≥áÊñôÈõÜË®≠ÂÆö‰πüÊúÉË¢´ÂøΩÁï•„ÄÇ\n",
        "\n",
        "‰Ω†ÂèØ‰ª•Âä†ÂÖ• `√¨s_reg = true` Â∞áÊüê‰∏ÄÂÄãË≥áÊñôÈõÜË®≠ÂÆöÁÇ∫Ê≠£Ë¶èÂåñÔºàregularizationÔºâË≥áÊñô„ÄÇ\n",
        "‰Ω†‰πüÂèØ‰ª•Ë®≠ÂÆöÂêÑÁ®Æ‰∏çÂêåÁöÑÂèÉÊï∏Ôºå‰æãÂ¶Ç `keep_tokens`, `flip_aug` Á≠âÁ≠â„ÄÇ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y037lagnJWmn"
      },
      "outputs": [],
      "source": [
        "custom_dataset = \"\"\"\n",
        "[[datasets]]\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/example/dataset/good_images\"\n",
        "num_repeats = 3\n",
        "is_reg = false\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/example/dataset/normal_images\"\n",
        "num_repeats = 1\n",
        "is_reg = false\n",
        "\n",
        "[[datasets.subsets]]\n",
        "image_dir = \"/content/drive/MyDrive/Loras/example/dataset/reg_images\"\n",
        "num_repeats = 1\n",
        "is_reg = true\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W84Jxf-U2TIU"
      },
      "outputs": [],
      "source": [
        "custom_dataset = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sy9jU2yrdYar"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üîÆ ÈÄ≤ÈöéË®≠ÂÆö\n",
        "#@markdown ÊîπËÆäË®ìÁ∑¥ÊôÇ‰ΩøÁî®ÁöÑÂÑ™ÂåñÂô®Ôºå`AdamW8bit` ÊòØÊé®Ëñ¶ÁöÑÈ†êË®≠ÂÄº„ÄÇ\n",
        "#@markdown ÈÅ∏Êìá DAdaptation ÂÑ™ÂåñÂô®ÔºàÊúÉ‰ΩøÁî®Ëá™ÂãïÁÆ°ÁêÜÂ≠∏ÁøíÁéáÔºâÊúÉË¶ÜËìã‰ª•‰∏ãË®≠ÂÆöÔºö\n",
        "#@markdown `learning_rate=0.5`, `lr_scheduler=\"constant_with_warmup\"`, `optimizer_args=decouple=True,weight_decay=0.02`, `network_alpha=network_dim`\n",
        "optimizer = \"AdamW8bit\" #@param [\"AdamW8bit\", \"AdamW\", \"Lion\", \"DAdaptation\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
        "optimizer_args = \"weight_decay=0.1\" #@param {type:\"string\"}\n",
        "optimizer_args = [a.strip() for a in optimizer_args.split(\",\") if a]\n",
        "\n",
        "#@markdown Ê¨äÈáçÊ®ôÁ±§ÊòØ‰∏ÄÂÄãÊñ∞ÂäüËÉΩÔºåÂÖÅË®±‰Ω†‰ΩøÁî®ÔºàÊã¨ËôüÔºâ‰æÜÁµ¶‰∫àË≥áÊñôÈõÜ‰∏≠Êüê‰∫õÊ®ôÁ±§Êõ¥Â§öÁöÑÊ¨äÈáçÔºåÂ∞±ÂÉèÂú®Á∂≤È†ÅÁïåÈù¢ÊèêÁ§∫‰∏≠‰∏ÄÊ®£„ÄÇ\n",
        "#@markdown Ê≠£Â∏∏Êã¨ËôüÂú®‰Ω†ÁöÑÊ®ôÁ±§‰∏≠Ôºå‰æãÂ¶Ç `(series names)`ÔºåÈúÄË¶ÅÂÉè `\\(series names\\)` ÈÄôÊ®£Ë∑≥ËÑ´„ÄÇ\n",
        "weighted_captions = False #@param {type:\"boolean\"}\n",
        "\n",
        "#markdown By enabling `adjust_tags`, you will let this colab modify your tags before running to automatically adjust to `weighted_captions` being on or off. \n",
        "#@markdown Ëã•ÂïüÁî® `adjust_tags`Ôºå‰Ω†Â∞áÂÖÅË®±Ê≠§ colab Âú®Âü∑Ë°åÂâç‰øÆÊîπ‰Ω†ÁöÑÊ®ôÁ±§Ôºå‰ª•Ëá™ÂãïË™øÊï¥ `weighted_captions` ÁöÑÈñãÈóú„ÄÇ\n",
        "adjust_tags = False #@param {type:\"boolean\"}\n",
        "activation_tag_weight = \"1.0\" #@param [\"1.0\",\"1.1\",\"1.2\"]\n",
        "keep_tokens_weight = float(activation_tag_weight)\n",
        "\n",
        "#@markdown ‰Ω†ÂèØ‰ª•Âú®ÈÄôË£°ÂØ´‰∏ã‰Ω†ÁöÑ Google Drive ‰∏≠ÁöÑË∑ØÂæëÔºå‰ª•ËºâÂÖ•ÁèæÊúâÁöÑ Lora Ê™îÊ°àÔºå‰ª•ÁπºÁ∫åË®ìÁ∑¥„ÄÇ\n",
        "#@markdown **Ë≠¶Âëä** ÈÄô‰∏çÊòØ‰∏ÄÂÄãÈï∑ÊôÇÈñìÁöÑË®ìÁ∑¥ÈöéÊÆµ„ÄÇÊØèÂÄã epoch ÈÉΩÊòØÂæûÈ†≠ÈñãÂßãÔºå‰∏¶‰∏îÂèØËÉΩÊúÉÊúâÊõ¥Â∑ÆÁöÑÁµêÊûú„ÄÇ\n",
        "continue_from_lora = \"\" #@param {type:\"string\"}\n",
        "if continue_from_lora and not continue_from_lora.startswith(\"/content/drive/MyDrive\"):\n",
        "  import os\n",
        "  continue_from_lora = os.path.join(\"/content/drive/MyDrive\", continue_from_lora)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WDjkp4scvPgE"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üìÇ Ëß£Â£ìÁ∏ÆË≥áÊñôÈõÜ\n",
        "#@markdown ‰∏äÂÇ≥Ë≥áÊñôÈõÜÊ™îÊ°àÊòØ‰∏ÄÂÄãÂæàÊÖ¢ÁöÑÈÅéÁ®ãÔºåÂ¶ÇÊûú‰Ω†Êúâ‰∏ÄÂÄã zip Ê™îÊ°àÔºå‰Ω†ÂèØËÉΩÊÉ≥Ë¶Å‰∏äÂÇ≥‰∏ÄÂÄã zip Ê™îÊ°àÂà∞‰Ω†ÁöÑÈõ≤Á´ØÁ°¨Á¢ü„ÄÇ\n",
        "zip = \"/content/drive/MyDrive/my_dataset.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"üìÇ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKWlpsG0jrX3"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üî¢ Ë®àÁÆóË≥áÊñôÈõÜ\n",
        "#@markdown Google Drive ÁÑ°Ê≥ïË®àÁÆóË≥áÊñôÂ§æ‰∏≠ÁöÑÊ™îÊ°àÊï∏ÔºåÂõ†Ê≠§ÈÄôÂ∞áÈ°ØÁ§∫ÊâÄÊúâË≥áÊñôÂ§æÂíåÂ≠êË≥áÊñôÂ§æ‰∏≠ÁöÑÊ™îÊ°àÊï∏„ÄÇ\n",
        "folder = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
